\input{header.tex}

\title{3 -- Private Key Encryption}

\newcommand*{\PrivKExpt}[2]{\operatorname{PrivK}_{#2}^{\textrm{#1}}}
\newcommand*{\PrivKOut}[2]{\operatorname{PrivKOut}_{#2}^{\textrm{#1}}}

\begin{document}

\maketitle
\initMinimal{}

\tableofcontents

\section{Computational Security}

\subsection{Definition of relaxations}

Unlike perfect security, we make 2 additional assumptions to make
secure encryption practical:
\begin{itemize}
\item Adversaries are \textbf{efficient} and only run for a feasible amount of time.
\item Adversaries have a \textbf{negligible} probability of success.
\end{itemize}

All encryption schemes are parametrized by a security parameter $n$.
$n$ is usually the key length.
The terms `efficient' and `negligible' are defined in terms of $n$.

\begin{definition}
An efficient adversary is a probabilistic polynomial-time (PPT) algorithm,
where the input is at least as large as the security parameter.
\end{definition}
\begin{definition}
A function $f:\mathbb{N} \mapsto \mathbb{R}$ is negligible iff
\[ f(n) \in \bigcap_{k \in \mathbb{N}} o(n^{-k}) = \operatorname{negl}(n) \]
\end{definition}

\begin{theorem}
\[ f \textrm{ is negligible} \iff \forall p(x) \in \mathbb{R}[x],
\exists N \in \mathbb{N}, \forall n \ge N, f(n) < \frac{1}{p(n)} \]
\end{theorem}
\begin{theorem}
\[ f \textrm{ is negligible} \implies (\forall p(x) \in \mathbb{R}[x], p(n)f(n) \textrm{ is negligible}) \]
\end{theorem}

\subsection{[Draft] Necessity of the relaxations}

(TODO: Needs rigor)

\begin{itemize}
\item Powerful adversary can brute force the set of keys to break scheme with very high probability.
\item Normal adversary can guess key and break scheme with slightly higher probability than pure guess.
\end{itemize}

\section{Defining Computationally Secure Encryption}

\begin{itemize}
\item The key-generation algorithm $\textsf{Gen}$ takes input $1^n$ and returns key $k$.
We assume (why?) that $|k| \ge n$.
\item The encryption algorithm $\textsf{Enc}$ takes the key and message as input and outputs a ciphertext.
\item The decryption algorithm $\textsf{Dec}$ takes the key and ciphertext as input and outputs a message.
\end{itemize}

\begin{definition}
The adversarial indistinguishability experiment $\PrivKExpt{eav}{A,\Pi}(n)$:
\begin{enumerate}
\item $A$ is given input $1^n$. It outputs 2 messages $m_0$ and $m_1$ with $|m_0| = |m_1|$.
\item $k \in \mathcal{K}$ is generated by running $\textsf{Gen}(1^n)$.
$b$ is chosen uniformly randomly from $\{0, 1\}$.
$c = e_k(m)$, called the challenge ciphertext, is computed and given to $A$.
\item $A$ outputs a bit $b'$.
\item $\PrivKExpt{eav}{A,\Pi}(n) = \begin{cases}1 & \textrm{ if } b' = b \\ 0 & \textrm{ if } b' \neq b\end{cases}$.
\end{enumerate}
\end{definition}

Messages output by adversary are required to be of the same length
otherwise adversary can use ciphertext length to determine which message was encrypted.

\begin{definition}
Scheme $\Pi$ is EAV-secure iff for every PPT adversary $A$,
\[ \Pr\left[ \PrivKExpt{eav}{A,\Pi}(n) = 1\right]
\le \frac{1}{2} + \operatorname{negl}(n) \]
\end{definition}

\begin{definition}
Let $\PrivKExpt{eav}{A,\Pi}(n, b)$ be the experiment where the message chosen by the challenger
is fixed to be $m_b$ (instead of choosing uniformly randomly from $\{m_0, m_1\}$),
but the adversary doesn't know this.
Let $\PrivKOut{eav}{A,\Pi}(n, b)$ be the output $b'$ of the adversary.
\end{definition}

\begin{theorem}
$\Pi$ is secure iff for all PPT adversaries $A$,
\[ \left| \Pr\left[ \PrivKOut{eav}{A,\Pi}(n, 1) = 1 \right]
- \Pr\left[ \PrivKOut{eav}{A,\Pi}(n, 0) = 1 \right] \right| \in \operatorname{negl}(n) \]
\end{theorem}

\end{document}
